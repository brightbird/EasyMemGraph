# å¿†è¯­ (YiYu) å¼€å‘æŒ‡å—

## ğŸš¨ æ ¸å¿ƒå¼€å‘åŸåˆ™

1. **å§‹ç»ˆåœ¨åŸºäº Python 3.11 çš„è™šæ‹Ÿç¯å¢ƒä¸‹æ‰§è¡Œä»£ç **
   ```bash
   # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
   source venv/bin/activate

   # éªŒè¯ Python ç‰ˆæœ¬
   python --version  # åº”æ˜¾ç¤º Python 3.11.x
   ```

2. **ä¸¥ç¦ä½¿ç”¨ä»»ä½•é™çº§å¤„ç†æ–¹å¼ï¼Œä¸¥æ ¼æŒ‰è¦æ±‚çš„æ–¹æ¡ˆå®ç°**
   - ä¸å¯ä½¿ç”¨ API å¤‡ç”¨æ–¹æ¡ˆ
   - ä¸å¯æœ‰é”™è¯¯å¤„ç†çš„é™çº§é€»è¾‘
   - å¿…é¡»ç¡®ä¿æ‰€æœ‰ç»„ä»¶æŒ‰é…ç½®æ­£å¸¸å·¥ä½œ

## ğŸ—ï¸ é¡¹ç›®æ¶æ„æ¦‚è§ˆ

### ç³»ç»Ÿæ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚   LangGraph      â”‚    â”‚    ModelScope   â”‚
â”‚   Webç•Œé¢       â”‚â”€â”€â”€â–¶â”‚   å¯¹è¯çŠ¶æ€ç®¡ç†   â”‚â”€â”€â”€â–¶â”‚   LLM APIæœåŠ¡   â”‚
â”‚   (app.py)      â”‚    â”‚ (memory_agent.py)â”‚    â”‚ DeepSeek-V3.1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚      Mem0        â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚   è®°å¿†ç®¡ç†ç³»ç»Ÿ   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     Qdrant       â”‚
                        â”‚   æœ¬åœ°å‘é‡æ•°æ®åº“  â”‚
                        â”‚  (M3E-Base 768ç»´) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    LangSmith     â”‚
                        â”‚   å¯¹è¯æµç¨‹è¿½è¸ª   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ¨¡å—ç»“æ„
- **app.py**: Streamlit Webåº”ç”¨ä¸»æ–‡ä»¶ï¼Œæ™ºèƒ½ç”¨æˆ·ç®¡ç†
- **memory_agent.py**: ä¸»å¯¹è¯ä»£ç†ï¼Œé›†æˆLangSmithè¿½è¸ª
- **config.py**: ç»Ÿä¸€é…ç½®ç®¡ç†ï¼Œç¯å¢ƒå˜é‡å¤„ç†
- **setup_qdrant.py**: Qdrantå‘é‡æ•°æ®åº“åˆå§‹åŒ–
- **langsmith_debug.py**: LangSmithè°ƒè¯•å’Œç›‘æ§å·¥å…·
- **setup_langsmith_project.py**: LangSmithé¡¹ç›®è®¾ç½®

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒé…ç½®

### è™šæ‹Ÿç¯å¢ƒç®¡ç†
```bash
# åˆ›å»ºæ–°çš„ Python 3.11 è™šæ‹Ÿç¯å¢ƒ
python3.11 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# å‡çº§pip
pip install --upgrade pip

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python -c "import langgraph, mem0, qdrant_client, streamlit; print('âœ… æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ')"
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# å¿…é¡»é…ç½®çš„å…³é”®å‚æ•°
MODELSCOPE_API_KEY=your-modelscope-api-key-here
LANGCHAIN_API_KEY=your-langsmith-api-key-here

# æ¨èé…ç½®å‚æ•°
EMBEDDING_MODEL=moka-ai/m3e-base
EMBEDDING_DIMS=768
MODEL_NAME=deepseek-ai/DeepSeek-V3.1
QDRANT_URL=http://localhost:6333
LANGCHAIN_PROJECT=YiYu
```

## ğŸ“¦ æŠ€æœ¯æ ˆè¯¦è§£

### æ ¸å¿ƒæ¡†æ¶ (2025å¹´æœ€æ–°ç‰ˆæœ¬)
- **LangGraph (>=0.2.0)**: å¯¹è¯çŠ¶æ€ç®¡ç†å’Œæµç¨‹æ§åˆ¶
- **LangChain (>=0.3.0)**: LLMé›†æˆå’Œå·¥å…·é“¾
- **Mem0 (>=0.1.8)**: æ™ºèƒ½è®°å¿†ç®¡ç†ç³»ç»Ÿ
- **Qdrant-client (>=1.9.0)**: é«˜æ€§èƒ½å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯

### æ¨¡å‹å’ŒåµŒå…¥
- **ModelScope (>=1.17.0)**: é­”æ­ç¤¾åŒºæ¨¡å‹æœåŠ¡
- **Transformers (>=4.40.0)**: HuggingFaceæ¨¡å‹åº“
- **Torch (>=2.2.0)**: PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
- **M3E-Base**: ä¸­æ–‡åµŒå…¥æ¨¡å‹ (768ç»´å‘é‡)

### Webç•Œé¢å’Œå·¥å…·
- **Streamlit (>=1.28.0)**: ç°ä»£åŒ–Webåº”ç”¨æ¡†æ¶
- **Rich (>=13.7.0)**: ç»ˆç«¯ç¾åŒ–å’Œæ—¥å¿—è¾“å‡º
- **LangSmith (>=0.1.0)**: å¯¹è¯æµç¨‹è¿½è¸ªå’Œè°ƒè¯•

### æ¨¡å‹é…ç½®è¯¦æƒ…
- **LLM**: ModelScope DeepSeek-V3.1 (é«˜æ€§èƒ½å¯¹è¯æ¨¡å‹)
- **åµŒå…¥**: æœ¬åœ° M3E-Base (ä¸­æ–‡ä¼˜åŒ–ï¼Œ768ç»´)
- **å‘é‡å­˜å‚¨**: æœ¬åœ° Qdrant (Cosine è·ç¦»ç®—æ³•)
- **è®°å¿†ç®¡ç†**: Mem0æ™ºèƒ½è®°å¿†ç³»ç»Ÿ

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### å®Œæ•´æµ‹è¯•æµç¨‹
```bash
# 1. åŸºç¡€ç¯å¢ƒæµ‹è¯•
python -c "import langgraph, mem0, qdrant_client, streamlit; print('âœ… æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ')"

# 2. Qdrant è¿æ¥æµ‹è¯•
python -c "from qdrant_client import QdrantClient; client = QdrantClient('http://localhost:6333'); print('âœ… Qdrantè¿æ¥æˆåŠŸ')"

# 3. åµŒå…¥æ¨¡å‹æµ‹è¯•
python -c "from sentence_transformers import SentenceTransformer; model = SentenceTransformer('moka-ai/m3e-base'); print('âœ… M3E-Baseæ¨¡å‹åŠ è½½æˆåŠŸ')"

# 4. å®Œæ•´åŠŸèƒ½æµ‹è¯• (æ¨è)
python test_agent.py

# 5. å•æ¬¡å¯¹è¯æµ‹è¯•
python -c "from memory_agent import run_conversation; print(run_conversation('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±', 'test_user'))"

# 6. LangSmith è¿½è¸ªæµ‹è¯•
python langsmith_debug.py test --input "æµ‹è¯•æ¶ˆæ¯" --user-id test_user
```

### éªŒè¯æ¸…å•
- [ ] Python 3.11 è™šæ‹Ÿç¯å¢ƒæ¿€æ´»
- [ ] æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ
- [ ] ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡® (MODELSCOPE_API_KEY, LANGCHAIN_API_KEY)
- [ ] Qdrant æœåŠ¡æ­£å¸¸è¿è¡Œ (http://localhost:6333)
- [ ] åµŒå…¥æ¨¡å‹æœ¬åœ°åŠ è½½æˆåŠŸ (M3E-Base)
- [ ] LLM API è°ƒç”¨æˆåŠŸ (ModelScope DeepSeek-V3.1)
- [ ] è®°å¿†åŠŸèƒ½æ­£å¸¸å·¥ä½œ (Mem0)
- [ ] ç”¨æˆ·éš”ç¦»æœ‰æ•ˆ
- [ ] LangSmith è¿½è¸ªæ­£å¸¸
- [ ] Webç•Œé¢å¯ä»¥æ­£å¸¸å¯åŠ¨

## ğŸ”§ ä»£ç è§„èŒƒ

### é…ç½®ç®¡ç†
- ä½¿ç”¨ `config.py` ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®
- ç¯å¢ƒå˜é‡é€šè¿‡ `.env` æ–‡ä»¶é…ç½®
- ä¸ç¡¬ç¼–ç ä»»ä½•é…ç½®å‚æ•°
- æ•æ„Ÿä¿¡æ¯ (API keys) ä»…é€šè¿‡ç¯å¢ƒå˜é‡ä¼ é€’

### é”™è¯¯å¤„ç†
- **ç¦æ­¢**ä½¿ç”¨ try-except è¿›è¡Œé™çº§å¤„ç†
- **å¿…é¡»**åœ¨ç»„ä»¶æ•…éšœæ—¶ç›´æ¥æŠ¥é”™
- **ç¡®ä¿**æ‰€æœ‰ä¾èµ–æŒ‰é¢„æœŸå·¥ä½œ
- ä½¿ç”¨ Rich åº“ç¾åŒ–é”™è¯¯è¾“å‡º

### ä»£ç é£æ ¼
- éµå¾ª PEP 8 Python ä»£ç è§„èŒƒ
- ä½¿ç”¨ç±»å‹æç¤º (Type Hints)
- å‡½æ•°å’Œç±»å¿…é¡»åŒ…å«æ–‡æ¡£å­—ç¬¦ä¸²
- å˜é‡å‘½åä½¿ç”¨ snake_case

### è®°å¿†ç³»ç»Ÿè§„èŒƒ
- ä½¿ç”¨æœ¬åœ° M3E-Base åµŒå…¥æ¨¡å‹
- é€šè¿‡ Qdrant è¿›è¡Œå‘é‡å­˜å‚¨
- å®ç°ä¸¥æ ¼çš„ç”¨æˆ·éš”ç¦»
- è®°å¿†æ•°æ®è‡ªåŠ¨å»é‡å’Œæ›´æ–°

## ğŸ“ å¼€å‘å·¥ä½œæµç¨‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# éªŒè¯ç¯å¢ƒ
python --version  # ç¡®ä¿æ˜¯ Python 3.11.x
pip list | grep -E "(langgraph|mem0|qdrant|streamlit)"  # éªŒè¯å…³é”®ä¾èµ–
```

### 2. å¼€å‘å‰æ£€æŸ¥
```bash
# æ£€æŸ¥ Qdrant æœåŠ¡
curl http://localhost:6333/collections

# æ£€æŸ¥ç¯å¢ƒå˜é‡
python -c "import os; print('MODELSCOPE_API_KEY:', 'SET' if os.getenv('MODELSCOPE_API_KEY') else 'NOT SET')"
```

### 3. ä»£ç ä¿®æ”¹æµç¨‹
- éµå¾ªæ—¢å®šçš„æ¶æ„è®¾è®¡
- ä¿æŒé…ç½®çš„ç»Ÿä¸€ç®¡ç†
- ç¡®ä¿æ— é™çº§å¤„ç†
- å…ˆè¿è¡Œæµ‹è¯•å†ä¿®æ”¹ä»£ç 
- ä¿®æ”¹åç«‹å³æµ‹è¯•éªŒè¯

### 4. æµ‹è¯•éªŒè¯
```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_agent.py

# LangSmith è¿½è¸ªæµ‹è¯•
python langsmith_debug.py list --limit 5
```

### 5. æ–‡æ¡£æ›´æ–°
- æ›´æ–° README.md
- æ›´æ–°ç›¸å…³æ³¨é‡Š
- æ›´æ–° CLAUDE.md å¼€å‘æŒ‡å—

## ğŸš€ å¼€å‘è°ƒè¯•æŒ‡å—

### æœ¬åœ°å¼€å‘è°ƒè¯•
```bash
# å¯åŠ¨ Web ç•Œé¢è°ƒè¯•
streamlit run app.py --server.port 8501 --logger.level debug

# å¯åŠ¨å‘½ä»¤è¡Œè°ƒè¯•
python memory_agent.py

# æŸ¥çœ‹ LangSmith è¿½è¸ªæ•°æ®
python langsmith_debug.py monitor --duration 10
```

### æ€§èƒ½åˆ†æ
```bash
# åˆ†æå¯¹è¯æ€§èƒ½
python langsmith_debug.py performance --hours 24

# æŸ¥çœ‹ç”¨æˆ·ç»Ÿè®¡
python -c "
from app import get_user_statistics
print('ç”¨æˆ·ç»Ÿè®¡:', get_user_statistics())
"
```

### å†…å­˜å’Œèµ„æºç›‘æ§
```bash
# ç›‘æ§å†…å­˜ä½¿ç”¨
python -c "
import psutil
import os
process = psutil.Process(os.getpid())
print(f'å†…å­˜ä½¿ç”¨: {process.memory_info().rss / 1024 / 1024:.2f} MB')
"

# ç›‘æ§ GPU ä½¿ç”¨ (å¦‚æœæœ‰)
nvidia-smi  # Linux/Windows with NVIDIA GPU
```

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### å¼€å‘åŸåˆ™
- **æœ¬åœ°ä¼˜å…ˆ**: åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨å¿…é¡»æœ¬åœ°éƒ¨ç½²
- **ç”¨æˆ·éš”ç¦»**: ä¸åŒç”¨æˆ·æ•°æ®å®Œå…¨åˆ†ç¦»
- **æ— é™çº§**: ä»»ä½•ç»„ä»¶æ•…éšœéƒ½åº”ç›´æ¥æŠ¥é”™
- **ç‰ˆæœ¬æ§åˆ¶**: ä¸¥æ ¼ä½¿ç”¨ Python 3.11
- **é…ç½®ç»Ÿä¸€**: æ‰€æœ‰é…ç½®é€šè¿‡ config.py ç®¡ç†

### å®‰å…¨è€ƒè™‘
- API å¯†é’¥ä¸èƒ½æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
- ç”¨æˆ·æ•°æ®å®Œå…¨éš”ç¦»å­˜å‚¨
- æœ¬åœ°æ•°æ®åº“ç¡®ä¿æ•°æ®éšç§
- å®šæœŸå¤‡ä»½ Qdrant æ•°æ®

### æ€§èƒ½ä¼˜åŒ–
- åˆç†è®¾ç½®è®°å¿†æœç´¢é™åˆ¶ (limit=5)
- ä½¿ç”¨æµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ
- ç¼“å­˜å¸¸ç”¨é…ç½®å’Œæ¨¡å‹
- ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ

## ğŸ› æ•…éšœæ’é™¤æŒ‡å—

### è™šæ‹Ÿç¯å¢ƒé—®é¢˜
```bash
# å®Œå…¨é‡å»ºè™šæ‹Ÿç¯å¢ƒ
rm -rf venv
python3.11 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

### æ¨¡å‹ä¸‹è½½é—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç£ç›˜ç©ºé—´
df -h  # æŸ¥çœ‹ç£ç›˜ç©ºé—´
ping huggingface.co  # æµ‹è¯•ç½‘ç»œè¿æ¥

# æ¸…ç† HuggingFace ç¼“å­˜
rm -rf ~/.cache/huggingface
rm -rf ~/.cache/modelscope

# é‡æ–°ä¸‹è½½æ¨¡å‹
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('moka-ai/m3e-base')"
```

### Qdrant è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:6333/collections
curl http://localhost:6333/health

# é‡æ–°è®¾ç½® Qdrant
python setup_qdrant.py

# æ‰‹åŠ¨å¯åŠ¨ Docker (å¦‚æœéœ€è¦)
docker run -d --name qdrant-memory-agent \
  -p 6333:6333 -p 6334:6334 \
  -v $(pwd)/qdrant_storage:/qdrant/storage \
  qdrant/qdrant:latest
```

### API è°ƒç”¨é—®é¢˜
```bash
# æµ‹è¯• ModelScope API
python -c "
import os
from modelscope import AutoModelForCausalLM, AutoTokenizer
print('ModelScope API Key:', 'SET' if os.getenv('MODELSCOPE_API_KEY') else 'NOT SET')
"

# æµ‹è¯• LangSmith API
python -c "
import os
from langsmith import Client
print('LangSmith API Key:', 'SET' if os.getenv('LANGCHAIN_API_KEY') else 'NOT SET')
"
```

### å†…å­˜å’Œæ€§èƒ½é—®é¢˜
```bash
# ç›‘æ§ç³»ç»Ÿèµ„æº
htop  # Linux
top   # macOS/Linux
æ´»åŠ¨ç›‘è§†å™¨  # macOS

# æ¸…ç† Python ç¼“å­˜
find . -name "*.pyc" -delete
find . -name "__pycache__" -type d -exec rm -rf {} +
```

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰åµŒå…¥æ¨¡å‹
```python
# åœ¨ config.py ä¸­ä¿®æ”¹
EMBEDDING_MODEL = "your-custom-model"
EMBEDDING_DIMS = 1024  # æ ¹æ®æ¨¡å‹è°ƒæ•´
```

### è°ƒæ•´è®°å¿†æœç´¢å‚æ•°
```python
# åœ¨ memory_agent.py ä¸­è°ƒæ•´
memories = memory.search(
    query=user_message,
    user_id=user_id,
    limit=10,  # å¢åŠ æœç´¢ç»“æœæ•°é‡
    similarity_threshold=0.7  # è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼
)
```

### LangSmith é«˜çº§é…ç½®
```bash
# è®¾ç½®é‡‡æ ·ç‡
LANGCHAIN_TRACING_SAMPLE_RATE=1.0

# å¯ç”¨è¯¦ç»†æ—¥å¿—
LANGCHAIN_VERBOSE=true

# è®¾ç½®é¡¹ç›®æ ‡ç­¾
LANGCHAIN_TAGS="development,yiyu,memory-agent"
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### åº”ç”¨ç›‘æ§
```bash
# å®æ—¶ç›‘æ§ LangSmith è¿½è¸ª
python langsmith_debug.py monitor --duration 30

# æ€§èƒ½åˆ†ææŠ¥å‘Š
python langsmith_debug.py performance --hours 24 --output report.json

# é”™è¯¯æ—¥å¿—åˆ†æ
python langsmith_debug.py errors --hours 48
```

### æ—¥å¿—é…ç½®
```python
# åœ¨ä»£ç ä¸­å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# å¯ç”¨ç‰¹å®šæ¨¡å—çš„è°ƒè¯•æ—¥å¿—
logging.getLogger("langgraph").setLevel(logging.DEBUG)
logging.getLogger("mem0").setLevel(logging.DEBUG)
```

### ç³»ç»Ÿèµ„æºç›‘æ§
```bash
# CPU å’Œå†…å­˜ç›‘æ§
python -c "
import psutil
import time
while True:
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    print(f'CPU: {cpu_percent}%, å†…å­˜: {memory.percent}%')
    time.sleep(5)
"

# ç£ç›˜ç©ºé—´ç›‘æ§
df -h
du -sh qdrant_storage/
```

## ğŸš€ éƒ¨ç½²æŒ‡å—

### æœ¬åœ°éƒ¨ç½²
```bash
# 1. ç¯å¢ƒå‡†å¤‡
source venv/bin/activate
python setup_qdrant.py

# 2. å¯åŠ¨ Web æœåŠ¡
streamlit run app.py --server.port 8501

# 3. éªŒè¯éƒ¨ç½²
curl http://localhost:8501
```

### Docker éƒ¨ç½²
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8501 6333

# å¯åŠ¨è„šæœ¬
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t yiyu-memory-agent .
docker run -d --name yiyu \
  -p 8501:8501 -p 6333:6333 \
  -v $(pwd)/qdrant_storage:/app/qdrant_storage \
  --env-file .env \
  yiyu-memory-agent
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®
```bash
# ç¯å¢ƒå˜é‡ (ç”Ÿäº§ç¯å¢ƒ)
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
STREAMLIT_SERVER_ENABLE_CORS=false
STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION=true

# æ€§èƒ½ä¼˜åŒ–
PYTHONUNBUFFERED=1
TZ=Asia/Shanghai
```

## ğŸ”„ æ•°æ®å¤‡ä»½å’Œæ¢å¤

### Qdrant æ•°æ®å¤‡ä»½
```bash
# 1. åœæ­¢ Qdrant æœåŠ¡
docker stop qdrant-memory-agent

# 2. å¤‡ä»½æ•°æ®ç›®å½•
tar -czf qdrant_backup_$(date +%Y%m%d_%H%M%S).tar.gz qdrant_storage/

# 3. æ¢å¤æ•°æ®
tar -xzf qdrant_backup_YYYYMMDD_HHMMSS.tar.gz

# 4. é‡å¯æœåŠ¡
docker start qdrant-memory-agent
```

### é…ç½®æ–‡ä»¶å¤‡ä»½
```bash
# å¤‡ä»½å…³é”®é…ç½®
cp .env .env.backup
cp config.py config.py.backup

# æ‰¹é‡å¤‡ä»½è„šæœ¬
#!/bin/bash
BACKUP_DIR="backup_$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

cp .env $BACKUP_DIR/
cp config.py $BACKUP_DIR/
cp -r qdrant_storage $BACKUP_DIR/
tar -czf $BACKUP_DIR.tar.gz $BACKUP_DIR/
rm -rf $BACKUP_DIR/

echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR.tar.gz"
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ¨¡å‹ä¼˜åŒ–
```python
# ä¼˜åŒ–åµŒå…¥æ¨¡å‹é…ç½®
from sentence_transformers import SentenceTransformer

# ä½¿ç”¨ GPU åŠ é€Ÿ (å¦‚æœå¯ç”¨)
model = SentenceTransformer('moka-ai/m3e-base', device='cuda')

# æ‰¹é‡å¤„ç†æå‡æ•ˆç‡
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)
```

### æ•°æ®åº“ä¼˜åŒ–
```python
# Qdrant è¿æ¥ä¼˜åŒ–
from qdrant_client import QdrantClient

# ä½¿ç”¨è¿æ¥æ± 
client = QdrantClient(
    url="localhost",
    port=6333,
    timeout=30,
    prefer_grpc=True  # ä½¿ç”¨ gRPC æå‡æ€§èƒ½
)

# æ‰¹é‡æ“ä½œä¼˜åŒ–
def batch_search(client, queries, batch_size=10):
    results = []
    for i in range(0, len(queries), batch_size):
        batch = queries[i:i+batch_size]
        batch_results = client.search_batch(batch)
        results.extend(batch_results)
    return results
```

### ç¼“å­˜ç­–ç•¥
```python
# ä½¿ç”¨ functools.lru_cache ç¼“å­˜ç»“æœ
from functools import lru_cache
import time

@lru_cache(maxsize=100)
def cached_embedding(text: str):
    """ç¼“å­˜åµŒå…¥è®¡ç®—ç»“æœ"""
    # å®é™…çš„åµŒå…¥è®¡ç®—é€»è¾‘
    return compute_embedding(text)

# å®šæœŸæ¸…ç†ç¼“å­˜
def clear_cache_periodically():
    while True:
        time.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
        cached_embedding.cache_clear()
```

## ğŸ¯ æœ€ä½³å®è·µ

### å¼€å‘æœ€ä½³å®è·µ
1. **ç‰ˆæœ¬æ§åˆ¶**
   - ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬å· (v1.0.0)
   - æ¯ä¸ªåŠŸèƒ½ä½¿ç”¨ç‹¬ç«‹åˆ†æ”¯å¼€å‘
   - æäº¤ä¿¡æ¯ä½¿ç”¨çº¦å®šå¼æäº¤æ ¼å¼

2. **æµ‹è¯•é©±åŠ¨å¼€å‘**
   ```bash
   # å…ˆå†™æµ‹è¯•
   python test_agent.py

   # å†ä¿®æ”¹ä»£ç 
   # å†æ¬¡è¿è¡Œæµ‹è¯•éªŒè¯
   ```

3. **ä»£ç è´¨é‡**
   - ä½¿ç”¨ `black` æ ¼å¼åŒ–ä»£ç 
   - ä½¿ç”¨ `flake8` æ£€æŸ¥ä»£ç é£æ ¼
   - ä½¿ç”¨ `mypy` è¿›è¡Œç±»å‹æ£€æŸ¥

### è¿ç»´æœ€ä½³å®è·µ
1. **ç›‘æ§å‘Šè­¦**
   ```bash
   # è®¾ç½®å¥åº·æ£€æŸ¥
   curl -f http://localhost:8501/_stcore/health || exit 1

   # ç›‘æ§å…³é”®æŒ‡æ ‡
   python -c "
   from langsmith import Client
   client = Client()
   # æ£€æŸ¥æœ€è¿‘çš„é”™è¯¯ç‡
   "
   ```

2. **æ—¥å¿—ç®¡ç†**
   - ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
   - è®¾ç½®æ—¥å¿—è½®è½¬ç­–ç•¥
   - å…³é”®æ“ä½œæ·»åŠ å®¡è®¡æ—¥å¿—

3. **å®‰å…¨å®è·µ**
   - å®šæœŸæ›´æ–°ä¾èµ–åŒ…
   - ä½¿ç”¨ `.env.example` ä½œä¸ºé…ç½®æ¨¡æ¿
   - API å¯†é’¥ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†

### æ‰©å±•å¼€å‘æŒ‡å—
1. **æ·»åŠ æ–°çš„ LLM æä¾›å•†**
   ```python
   # åœ¨ config.py ä¸­æ·»åŠ æ–°çš„é…ç½®
   class NewLLMConfig:
       api_key: str = os.getenv("NEW_LLM_API_KEY")
       model_name: str = "new-model-name"
       base_url: str = "https://api.newllm.com"
   ```

2. **è‡ªå®šä¹‰è®°å¿†ç­–ç•¥**
   ```python
   # æ‰©å±• Mem0 é…ç½®
   custom_memory_config = {
       "vector_store": {
           "provider": "qdrant",
           "config": {
               "collection_name": "custom_memories",
               "embedding_model": "custom-model"
           }
       }
   }
   ```

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- [LangGraph å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [Mem0 æ–‡æ¡£](https://docs.mem0.ai/)
- [Qdrant æ–‡æ¡£](https://qdrant.tech/documentation/)
- [Streamlit æ–‡æ¡£](https://docs.streamlit.io/)
- [LangSmith æ–‡æ¡£](https://docs.smith.langchain.com/)

### ç¤¾åŒºèµ„æº
- [ModelScope é­”æ­ç¤¾åŒº](https://modelscope.cn/)
- [HuggingFace æ¨¡å‹åº“](https://huggingface.co/)
- [M3E æ¨¡å‹ä»“åº“](https://huggingface.co/moka-ai/m3e-base)

### ç›¸å…³å·¥å…·
- [Rich åº“](https://rich.readthedocs.io/) - ç»ˆç«¯ç¾åŒ–
- [Pydantic](https://pydantic-docs.helpmanual.io/) - æ•°æ®éªŒè¯
- [Python-dotenv](https://github.com/theskumar/python-dotenv) - ç¯å¢ƒå˜é‡ç®¡ç†

---

**ğŸ“… æœ€åæ›´æ–°**: 2025å¹´10æœˆ12æ—¥
**ğŸ”§ ç»´æŠ¤è€…**: å¿†è¯­ (YiYu) å¼€å‘å›¢é˜Ÿ
**ğŸ“¦ ç‰ˆæœ¬**: v2.0 (å¢å¼ºå¼€å‘æŒ‡å—)

è¿™ä»½å¼€å‘æŒ‡å—æ¶µç›–äº†å¿†è¯­é¡¹ç›®çš„å®Œæ•´å¼€å‘æµç¨‹ï¼ŒåŒ…æ‹¬ç¯å¢ƒé…ç½®ã€å¼€å‘è°ƒè¯•ã€æµ‹è¯•éªŒè¯ã€éƒ¨ç½²è¿ç»´ç­‰å„ä¸ªæ–¹é¢ã€‚è¯·æ ¹æ®å®é™…éœ€æ±‚å®šæœŸæ›´æ–°å’Œå®Œå–„ã€‚